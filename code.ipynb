{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d124098",
   "metadata": {},
   "source": [
    "# Processing video to generate transcripts and save in chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2fe1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "import moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90783592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "video = \"test_video.mp4\"\n",
    "\n",
    "VideoFileClip(video).audio.write_audiofile(\"audio.wav\", codec='pcm_s16le')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c1def",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"key.txt\", \"r\") as f:\n",
    "    key = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d954042",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "audio = AudioSegment.from_wav(\"audio.wav\")\n",
    "\n",
    "# chunk length ( 1 minute vids)\n",
    "chunk_length_ms = 1 * 60 * 1000 \n",
    "\n",
    "\n",
    "output_dir = \"chunks\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i in range(0, len(audio), chunk_length_ms):\n",
    "    chunk = audio[i:i + chunk_length_ms]\n",
    "    chunk_name = os.path.join(output_dir, f\"chunk_{i // chunk_length_ms + 1}.wav\")\n",
    "    chunk.export(chunk_name, format=\"wav\")\n",
    "    print(f\"Exported {chunk_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_audio = \"chunks\\chunk_1.wav\"\n",
    "\n",
    "\n",
    "with open(filename_audio, \"rb\") as file:\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "        file=(filename_audio, file.read()),\n",
    "        model=\"whisper-large-v3\",\n",
    "        response_format=\"verbose_json\",\n",
    "    )\n",
    "    print(transcription.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449365b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "chunk_dir = \"chunks\"\n",
    "transcript_dict = {}\n",
    "\n",
    "for chunk_file in sorted(os.listdir(chunk_dir)):\n",
    "    if not chunk_file.endswith(\".wav\"):\n",
    "        continue\n",
    "\n",
    "    filename_audio = os.path.join(chunk_dir, chunk_file)\n",
    "    print(f\"\\n Transcribing {chunk_file}...\")\n",
    "\n",
    "    with open(filename_audio, \"rb\") as file:\n",
    "        total_size = os.path.getsize(filename_audio)\n",
    "        \n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=f\"Uploading {chunk_file}\") as pbar:\n",
    "            file_content = file.read(1024 * 1024)\n",
    "            content = b\"\"\n",
    "\n",
    "            while file_content:\n",
    "                content += file_content\n",
    "                pbar.update(len(file_content))\n",
    "                file_content = file.read(1024 * 1024)\n",
    "\n",
    "\n",
    "    try:\n",
    "        chunk_num = int(''.join(filter(str.isdigit, chunk_file)))\n",
    "    except ValueError:\n",
    "        chunk_num = chunk_file  \n",
    "\n",
    "    # Send to groq API. \n",
    "    try:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            file=(chunk_file, content),\n",
    "            model=\"whisper-large-v3\",\n",
    "            response_format=\"verbose_json\",\n",
    "        )\n",
    "        transcript_dict[chunk_num] = transcription.text\n",
    "        print(\" Transcription:\", transcription.text)\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to transcribe {chunk_file}: {e}\")\n",
    "\n",
    "# (Optional) print final dict keys\n",
    "print(\"\\n Final transcript dictionary keys:\", list(transcript_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea1132",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908f3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dictionary\n",
    "sorted_transcript_dict = {k: transcript_dict[k] for k in sorted(transcript_dict)}\n",
    "\n",
    "sorted_transcript_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86051e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_data = json.dumps(sorted_transcript_dict, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7c387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON file\n",
    "with open(\"sorted_transcript.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sorted_transcript_dict, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\" JSON saved as sorted_transcript.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff45010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43239cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(page_content=chunk, metadata={\"chunk_id\": chunk_id})\n",
    "    for chunk_id, chunk in sorted_transcript_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_lecture_db\"\n",
    ")\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cbe8bf",
   "metadata": {},
   "source": [
    "# Processing PPT and extracting various fields like heading, subheading, slide number, text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccfc47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pptx import Presentation\n",
    "from pptx.enum.shapes import MSO_SHAPE_TYPE\n",
    "from PIL import Image\n",
    "\n",
    "def extract_pptx_content(pptx_path, output_dir=r'<project directory>/extracted', json_file='slides_data.json'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    prs = Presentation(pptx_path)\n",
    "    slides_data = []\n",
    "\n",
    "    for i, slide in enumerate(prs.slides, start=1):\n",
    "        slide_data = {\n",
    "            \"slide_number\": i,\n",
    "            \"heading\": \"\",\n",
    "            \"subheading\": \"\",\n",
    "            \"text\": \"\",\n",
    "            \"images\": []\n",
    "        }\n",
    "\n",
    "        text_boxes = []\n",
    "\n",
    "        for shape in slide.shapes:\n",
    "            # Heading from title placeholder\n",
    "            if shape.is_placeholder and shape.placeholder_format.idx == 0 and shape.has_text_frame:\n",
    "                slide_data[\"heading\"] = shape.text.strip()\n",
    "\n",
    "            # Collect all text boxes\n",
    "            elif shape.has_text_frame:\n",
    "                text = shape.text.strip()\n",
    "                if text:\n",
    "                    text_boxes.append(text)\n",
    "\n",
    "            # Extract images\n",
    "            if shape.shape_type == MSO_SHAPE_TYPE.PICTURE:\n",
    "                image = shape.image\n",
    "                image_bytes = image.blob\n",
    "                image_ext = image.ext\n",
    "                image_filename = f\"{output_dir}/slide_{i}_image_{len(slide_data['images'])+1}.{image_ext}\"\n",
    "                with open(image_filename, 'wb') as f:\n",
    "                    f.write(image_bytes)\n",
    "                slide_data[\"images\"].append(image_filename)\n",
    "\n",
    "        # Assign subheading and main text\n",
    "        if text_boxes:\n",
    "            slide_data[\"subheading\"] = text_boxes[0]\n",
    "        if len(text_boxes) > 1:\n",
    "            slide_data[\"text\"] = \"\\n\".join(text_boxes[1:])\n",
    "\n",
    "        slides_data.append(slide_data)\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(slides_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Extraction complete. Data saved to {json_file} and images in '{output_dir}' folder.\")\n",
    "\n",
    "# Run it\n",
    "extract_pptx_content(\n",
    "    r\"<your lecture ppt>.pptx\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af763c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the unique topics from the json file\n",
    "\n",
    "import json\n",
    "\n",
    "def extract_unique_topics(json_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        slides_data = json.load(f)\n",
    "\n",
    "    topics = set()\n",
    "\n",
    "    for slide in slides_data:\n",
    "        subheading = slide.get(\"heading\", \"\").strip()\n",
    "        if subheading:\n",
    "            # Take only the first line if multi-line\n",
    "            main_line = subheading.split('\\n')[0].strip()\n",
    "            topics.add(main_line)\n",
    "\n",
    "    return list(topics)\n",
    "\n",
    "# Example usage\n",
    "topics_vector = extract_unique_topics('slides_data.json')\n",
    "print(topics_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63bef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "def build_topic_content_mapping(json_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        slides_data = json.load(f)\n",
    "\n",
    "    topic_map = defaultdict(str)\n",
    "    \n",
    "\n",
    "    for slide in slides_data:\n",
    "        subheading = slide.get(\"heading\", \"\").strip()\n",
    "        if subheading:\n",
    "            topic = subheading.split('\\n')[0].strip()  # Normalize topic name\n",
    "            text = slide.get(\"text\", \"\").strip()\n",
    "            if text:\n",
    "                topic_map[topic] += text + \"\\n\"\n",
    "\n",
    "    return dict(topic_map)\n",
    "\n",
    "# Usage\n",
    "topic_content_dict = build_topic_content_mapping(\"slides_data.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "topic_content_dict = build_topic_content_mapping(\"slides_data.json\")\n",
    "for topic, content in topic_content_dict.items():\n",
    "    print(f\"\\n=== {topic} ===\\n{content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c6ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_content_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a6a8d",
   "metadata": {},
   "source": [
    "# Langchain to generate notes from video and slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba94d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aef2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "f = open(\"key.txt\")\n",
    "key = f.read()\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0,\n",
    "    groq_api_key = key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01103503",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_temp = PromptTemplate.from_template(\n",
    "    '''\n",
    "    ### UNIVERSITY LECTURE TRANSCRIPT:\n",
    "    {lecture_transcript}\n",
    "\n",
    "    ### LECTURE SLIDE CONTENT:\n",
    "    {slides_content}\n",
    "\n",
    "    ###TOPIC:\n",
    "    {unique_topic}\n",
    "\n",
    "    ###INSTRUCTIONS:\n",
    "    You are John, An expert at making comprehensive academic notes. \n",
    "    You are required do exactly what you are good at. Given the lecture transcripts and the lecture slide content for a particular topic, generate\n",
    "    comprehensive lecture notes for the same covering all important details, merging the information from the slides and the transcripts.\n",
    "    ensure the text is correctly formatted.\n",
    "\n",
    "    DO NOT provide a preamble.\n",
    "    ### ANSWER (NO PREAMBLE):\n",
    "\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4795014",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_temp | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd6b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from markdown2 import markdown\n",
    "from xhtml2pdf import pisa\n",
    "\n",
    "# To store all markdown outputs\n",
    "final_md = \"\"\n",
    "\n",
    "for topic in topics_vector:\n",
    "    try: \n",
    "        slide_content = topic_content_dict[topic]\n",
    "    except :\n",
    "        continue\n",
    "    query = topic\n",
    "    results = vectordb.similarity_search(query, k=5)\n",
    "\n",
    "    transcript_content = \"\"\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        transcript_content += doc.page_content + \"\\n\"\n",
    "\n",
    "    res = chain.invoke({\n",
    "        \"lecture_transcript\": transcript_content,\n",
    "        \"slides_content\": slide_content,\n",
    "        \"unique_topic\": topic\n",
    "    })\n",
    "\n",
    "    # Append each topic's notes to final markdown string\n",
    "    final_md += f\"## {topic}\\n\\n{res.content}\\n\\n---\\n\\n\"\n",
    "\n",
    "# Convert markdown to HTML\n",
    "html_content = markdown(final_md)\n",
    "\n",
    "# Write HTML to PDF\n",
    "with open(\"qlora_lecture_notes.pdf\", \"wb\") as pdf_file:\n",
    "    pisa.CreatePDF(html_content, dest=pdf_file)\n",
    "\n",
    "print(\" PDF generated: qlora_lecture_notes.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a313845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (moviepy)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
